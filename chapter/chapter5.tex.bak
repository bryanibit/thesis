\chapter{实验结果分析}

\section{引言}
本文简述基于全景图像的二维地图构建与基于航拍图像的三维地图构建方法，构建适用于无人驾驶的地图，并对地图中的道路进行提取，构建拓扑路网。本章将从实验结果分析算法的有效性，实验分为三部分，二维、三维地图构建，道路提取，由于实验平台不同，将在各章节中独立介绍。实验将分析构图或道路提取的精度，并简述实验结果如何应用于无人驾驶中。
\section{全景图像构建地图实验结果}
\subsection{全景图像地图实验平台搭建}
本文提出的使用全景相机构建地图的方法使用的传感器包括Ladybug全景相机（图~\ref{ladybug}）、差分GPS与捷联惯性导航系统构成的高精度组合定位系统，通过标定全景相机与车体后轴中点的相对位置关系，得到全景相机球面坐标系与车体坐标系的旋转平移关系，最后将全景图像（图~\ref{raw-para}）变换为逆透视图像（图~\ref{IPM}），投影在地面中，依据定位信息将单帧图像拼接为大范围地图。除了传感器外，本节实验使用的计算机为运行Windows 7 的台式机，CPU 型号为英特尔酷睿i7-5930K，主频为3.5GHz，内存为4通道32GB。算法由C++语言实现，使用OpenCV开源库。由于本节构建地图的范围较大，而拼接的图像需要导入GIS 软件（SuperMap）生成金字塔图以便加快地图的缩放等操作，该过程是逐像素操作的，所以需要较大的计算量与较大的内存。


\subsection{全景图像地图构建效果及精度分析}

图~\ref{jiugong-ex}是使用本文提出的方法构建的二维地图，2016年于江苏常熟举办的无人车“未来挑战赛”采用该地图作为全局路径规划的基础，在无人车辆出发前，通过给定的任务点，依据地图信息进行全局路径规划，同时与GIS 软件结合，在无人车行驶过程中，为无人车提供道路先验信息等。
\begin{figure}[!htbp]
\centering
\subfigure[]{
\includegraphics[width=2.8in]{chapter5/panorama/jiugong_whole.jpg}}
\subfigure[]{
\includegraphics[width=2.2in]{chapter5/panorama/detail_jiugong.jpg}}
\caption{常熟无人车试验场}
\label{jiugong-ex}
\end{figure}

图~\ref{jiugong-ex}(b)为图~\ref{jiugong-ex}(a)的细节展示，其中(b)绿色方框内的点为无人车比赛时，车辆出发前路径规划得到的轨迹图，(b)上为左转变道过程，(b)下为U型转弯过程。图~\ref{sanhuan-ex}(a)为使用本节提出的方法构建的常熟三环路网地图，地图所占区域面积约为$12000\times 8000m$，三环道路的细节部分展示在图~\ref{sanhuan-ex}(b)(c)中，可以看出道路拼接良好，车道线存在轻微错位现象，但不影响实际比赛应用。

\begin{figure}[!htbp]
\centering
\subfigure[]{
\includegraphics[width=2.05in]{chapter5/panorama/sanhuan_whole.jpg}}
\subfigure[]{
\includegraphics[width=1.55in]{chapter5/panorama/detail3.jpg}}
\subfigure[]{
\includegraphics[width=1.6in]{chapter5/panorama/detail4.jpg}}
\caption{常熟三环路}
\label{sanhuan-ex}
\end{figure}

本节提出的构建适用于无人车行驶的二维地图，地图的精度很大程度取决于高精度组合定位系统的精度，因为每帧图片是按照定位系统输出的位置与航向拼接而成；其次需要考虑定位系统与全景相机的硬件同步，由于两个传感器采集频率不同，当采集到一帧图像时，对应该帧图像的车体位置（严格讲是全景相机位置）需要严格同步才可能做到高精度地图，最后就是全景图像逆透视变换时产生的形变也影响到构图的精度，尤其是本算法默认除车体以外其他区域的高度与地面相同，所以路边花坛、树木等变形较严重，无法作为后期制作地图的依据，这三方面误差是导致本节提出构建地图误差的主要来源。这些误差受制于传感器算法、地形等因素，所以很难量化，故在此不做详细讨论。本节提出的构建地图的方法分别应用于2016常熟“未来挑战赛”与军方总装的“跨越险阻”比赛中，在“未来挑战赛”中绝大部分地图区域拥有接近车道级别的构图精度，但是在“跨越险阻”比赛中，由于山地崎岖、颠簸严重，所以构图精度低于城市环境的“未来挑战赛”。

\section{地理空间三维重建实验结果}
\subsection{地理空间三维重建实验平台搭建}

\begin{figure}[!htbp]
	\centering
    \includegraphics[width=4.0in]{chapter5/reconstruction/experiment.png}
    \caption{DJI M100}
    \label{fig:djim}
\end{figure}

本节算法由C++/Python实现，SfM与MVS实现是基于OpenCV、openMVS、CeresSolver开源库，本研究使用运行Ubuntu 14.04 LTS操作系统的台式机，台式机CPU型号为英特尔酷睿i5-4570，CPU主频为3.2GHz，并配置8GB 单通道内存，没有配置独立显卡。航拍图像采集工具为大疆（DJI）M100无人机，如图~\ref{fig:djim}所示。图像分辨率为$4000\times 2240$，采集并存储于无人机相机的16GB SD卡中，用于本文实验后处理。

\subsection{三维重建效果及精度分析}

\begin{figure}[!htbp]
	\centering
	\includegraphics[width=5.8in]{chapter5/reconstruction/time-consume.png}
	\caption{实验耗时测量}
	\label{fig:time-consume}
\end{figure}
图~\ref{fig:time-consume}表示SfM过程两个数据集的耗时情况，其中数据集1表示雾岚山庄（56张图片），数据集2表示自动化学院（79张图片），实验调整图片分辨率为$2400\times 1350$。蓝色表示提取所有图片的SIFT 特征点并存储的耗时情况，黄色的耗时包括使用FLANN匹配特征点，并使用对极约束去除错误匹配，而后将所有图片的匹配关系用track序号表示的过程，绿色表示接下来的重建过程，包括初始化、增量式重建过程，系统在Python虚拟的多线程（4线程）上实现。

\begin{figure}[!htbp]
	\centering
	\includegraphics[width=5.8in]{chapter5/reconstruction/feature-filter.png}
	\caption{匹配特征点数量变化}
	\label{fig:feature-filter}
\end{figure}
三维重建的基础是正确的匹配数据集中所有图片的特征点，所以过滤错误的匹配特征点至关重要，图~\ref{fig:feature-filter}展示了不同方法过滤错误匹配特征点的情况，使用的数据集与上文描述相同。绿色表示使用Lowe提出的最近邻与次近邻比例小于$0.8$得到的匹配特征点数目。经过对极约束后剩下的特征点数目用黄色表示，即图片特征点与其对应极线距离不大于9个像素的特征点数目。在对极约束刷选结果基础上，通过匹配关系为每个特征点设置一个track序号，如果同一个track序号对应特征点所在视图存在名称相同的现象，则说明该匹配关系存在错误，删除该track序号对应的所有匹配特征点，剩余的特征点数目用蓝色表示。

\begin{figure}[!htbp]
	\centering
	\subfigure[稀疏点云]{
		\label{fig:sparse} %% label for first subfigure
		\includegraphics[width=2.95in]{chapter5/reconstruction/sparse_perspect.png}}
	\subfigure[稠密点云]{
		\label{fig:dense} %% label for first subfigure
		\includegraphics[width=2.95in]{chapter5/reconstruction/dense_perspect.png}}
	\caption{实验结果-雾岚山庄}
	\label{fig:wulan} %% label for entire figure
\end{figure}

如图~\ref{fig:wulan}所示，使用$54$张DJI航拍图像得到的稀疏点云（图~\ref{fig:sparse}）与稠密点云（图~\ref{fig:dense}），稀疏点云显示在RVIZ中，其中每个点都是提取的SIFT$\;$2D特征点还原的3D 点，稠密点云是使用基于深度图融合的方法得到并显示在Meshlab中。为了更好的衡量构图的精度，本文根据Turner\cite{Turner-Automated}测量构图精度的方法，同样采用设置地面控制点的方式，如图~\ref{example-gcp-image}所示，其中红色圆圈标记的白色纸张为设置的控制点。设置地面控制点的操作就是在构图区域使用高精度卫星定位系统测试真实场景某点（白色纸张的中心）的经纬度坐标，而后标记该场景所成二维图像中对应点的像素坐标（白纸中心成像后对应的像素坐标），如表~\ref{table:gcp} 所示。从而在构建三维地图的同时，根据已知控制点的绝对地理位置坐标与其像素坐标得到整个三维模型的地理空间尺度，可以直接作为GIS 数据库的输入数据，形成可以使用的地图信息。

\begin{figure}[!htbp]
\centering
\subfigure[]{
\includegraphics[width=2.95in]{chapter5/reconstruction/DJI_0104.JPG}
\label{example-gcp-image}}
\subfigure[]{\includegraphics[width=2.95in]{chapter5/reconstruction/sixbuild.PNG}
\label{example-gcp-sixbuild}}
\caption{地面控制点位置}
\end{figure}

本文在图~\ref{fig:wulan}场景中设置了9个地面控制点，最后根据成像模型测得这9个点的坐标与实际使用RTK GPS接收机测量的真实结果对比，如表~\ref{table:gcp_error}所示，每个测试点的精度分为东向与北向，二者的平方根表示在表最后一列为绝对误差，最后计算9个控制点的平均绝对误差为$1.586m$，由于地面控制点分布较均匀，而地图中某些区域，一般是边缘区域变形较大，导致平均误差较大。

\begin{table}[!htbp]
	\caption{地面控制点坐标}
	\centering
	\begin{tabular}{c|cccc}
		\hline
		\diagbox[dir=SE]{\bfseries 图片名称}{\bfseries 坐标名称} & \bfseries 东向 & \bfseries 北向 & \bfseries 图像X方向 & \bfseries 图像Y方向\\
		\hline

		\bfseries DJI\_0050.JPG &  $415462.60$ &  $4401226.15$ & $2706$ & $1615$\\

		\bfseries DJI\_0054.JPG & $415462.60$ & $4401226.15$ & $1312$ & $438$\\

        \bfseries DJI\_0052.JPG & $415462.60$ & $4401226.15$ & $2355$ & $440$\\

        \bfseries DJI\_0077.JPG & $415489.00$ & $4401201.80$ & $1011$ & $1033$\\

        \bfseries $\cdots\cdots$ & $\cdots\cdots$ & $\cdots\cdots$ & $\cdots\cdots$\\
		\hline
	\end{tabular}
	\label{table:gcp}
\end{table}


\begin{table}[!htbp]
	\caption{地面控制点误差测量}
	\centering
	\begin{tabular}{cccc}
		\hline
		\bfseries 控制点序号 & \bfseries 东向误差 & \bfseries 北向误差 & \bfseries 绝对误差\\
		\hline
%		\hline
		\bfseries 0 &  $0.093$ &  $0.095$ & $0.132$ \\
		\bfseries 1 & $0.267$ & $0.012$ & $0.268$ \\
        \bfseries 2 & $1.353$ & $2.165$ & $2.553$\\
        \bfseries 3 & $0.879$ & $1.888$ & $2.081$ \\
         \bfseries 4 & $0.260$ & $0.013$ & $0.261$ \\
        \bfseries 5 & $0.195$ & $1.542$ & $1.554$ \\
        \bfseries 6 & $2.148$ & $3.73$ & $4.311$ \\
        \bfseries 7 & $0.184$ & $0.207$ & $0.276$ \\
         \bfseries 8 & $1.298$ & $2.521$ & $2.8355$ \\
		\hline
	\end{tabular}
	\label{table:gcp_error}
\end{table}

与上文雾岚山庄数据集处理方法相似，通过79张图片可以得到自动化学院的三维地图结构，图~\ref{fig:sparse1}为稀疏点云在RVIZ中的显示效果，图~\ref{fig:dense1}为稠密点云在Meshlab中的显示效果图。该数据集同样设置地面控制点以衡量构图精度，共有三个地面控制点，控制点在整个构图区域的分布如图\ref{example-gcp-sixbuild}所示，该图是展示在Google Earth中的效果，可以看出没有设置落在构图边缘的控制点，控制点整体分布均匀。
\begin{figure}[!htbp]
	\centering
	\subfigure[稀疏点云]{
		\label{fig:sparse1} %% label for first subfigure
		\includegraphics[width=2.95in]{chapter5/reconstruction/sparse_perspect1.png}}
	\subfigure[稠密点云]{
		\label{fig:dense1} %% label for first subfigure
		\includegraphics[width=2.95in]{chapter5/reconstruction/dense_perspect1.png}}
	\caption{实验结果-自动化学院}
	\label{fig:6building} %% label for entire figure
\end{figure}

\begin{table}[!htbp]
	\caption{地面控制点误差测量}
	\centering
	\begin{tabular}{cccc}
		\hline
		\bfseries 控制点序号 & \bfseries 东向误差 & \bfseries 北向误差 & \bfseries 绝对误差\\
		\hline
%		\hline
		\bfseries 0 & $0.184$ & $0.378$ & $0.421$ \\
        \bfseries 1 & $0.856$ & $1.676$ & $1.883$\\
        \bfseries 2 & $0.141$ & $0.262$ & $0.298$ \\
		\hline
	\end{tabular}
	\label{table:gcp_error_six}
\end{table}

最后通过实验得到真实值与测量值的对比结果，如表~\ref{table:gcp_error_six} 所示，各列数据分别表示地面控制点的真实测量值与实验三维重建得到的模型对应点的东向、北向以及绝对误差值。由于三个点没有受到构图边缘变形的影响，所以结果稍好于好于雾岚山庄，得到平均控制点误差为$0.867m$。实际上由于本实验使用图片以及图片EXIF 信息中的经纬高数据，但是实际上EXIF 中的经纬高数据不是很准确，误差约$5m$，如果想要得到精度更高的地图，需要在构图时引入RTK，改善构图的精度。


\section{道路提取精度分析}
\begin{figure}[H]
	\centering
	\subfigure[RGB拟合]{
		\label{fig:subfig:RGB} %% label for first subfigure
		\includegraphics[width=1.14in]{chapter5/extraction/RGBOriginal.jpg}}
	\subfigure[开闭运算]{
		\label{fig:subfig:open} %% label for first subfigure
		\includegraphics[width=1.14in]{chapter5/extraction/openoperation.jpg}}
	%%\hspace{1in}
	\subfigure[非道路区域移除]{
		\label{fig:subfig:RemoveHouse} %% label for second subfigure
		\includegraphics[width=1.14in]{chapter5/extraction/removehouse.jpg}}
	\subfigure[拓扑细化]{
		\label{fig:subfig:first} %% label for first subfigure
		\includegraphics[width=1.14in]{chapter5/extraction/firstmiddlecenter.jpg}}
	\subfigure[实验拓扑]{
		\label{fig:subfig:finalroad} %% label for first subfigure
		\includegraphics[width=1.14in]{chapter5/extraction/finalmiddlecenter.jpg}}
	\caption{道路提取过程}
	\label{fig:subfig_results} %% label for entire figure
\end{figure}
\begin{figure}[H]
    \centering
    \subfigure[二维地图]{
    \label{resultSift}
    \includegraphics[width=1.6in]{chapter5/extraction/result_SIFT.jpg}}
    \subfigure[实验拓扑]{
		\label{fig:subfig:finalroad} %% label for first subfigure
		\includegraphics[width=1.5in]{chapter5/extraction/finalmiddlecenter.jpg}}
    \subfigure[真值拓扑]{
		\label{fig:subfig:real} %% label for first subfigure
		\includegraphics[width=1.5in]{chapter5/extraction/manual_real_road.jpg}}
%    \subfigure{
%    \includegraphics[width=2.8in]{chapter5/extraction/result_chart.png}}

    \caption{道路提取对比}
\end{figure}
根据第四章道路提取的方法，本节设计实验验证道路提取方法的精度。图~\ref{resultSift}是用来提取道路的二维地图，由于单张航拍二维图片表示的道路区域无法形成拓扑网络，所以从单张航拍图片中提取道路，而后根据航拍原图间的单应性关系拼接得到如图~\ref{resultSift}（原图拼接结果）和~\ref{fig:subfig:RGB}（单张图片RGB拟合结果），而后应用本文提出的道路提取方法精细道路区域，拓扑细化得到最后的实验结果。整个过程如图~\ref{fig:subfig_results}所示，其中图~\ref{fig:subfig:open}表示开闭运算平滑后的结果，图~\ref{fig:subfig:RemoveHouse}为移除矩形非道路区域后的结果，从中可以看出图左下方的房屋边沿被移除，图~\ref{fig:subfig:first}为采用RDP算法进行拓扑细化后的结果，可以看出初始拓扑有很多小枝丫，使用逐渐递减的阈值去除小枝丫后如图~\ref{fig:subfig:finalroad}所示。

使用道路提取的方法得到道路拓扑网络后，图~\ref{resultSift}分别展示了原图，提取道路（图~\ref{fig:subfig:finalroad}）与真实道路（图~\ref{fig:subfig:real}），两幅图中道路拓扑是由单像素构成，通过膨胀真实道路，计算提取道路的像素不在膨胀后的真实道路区域的比例，绘制图~\ref{curve}，其中横轴代表膨胀时使用的核函数的大小，单位是像素，而且一个像素代表地理空间约16$cm$，核函数越大，膨胀后的真实道路区域越大，不在膨胀区域的提取道路的像素越少。从图中可以看出核函数大小为$10$个像素，即$1.6m$时，有接近$90\%$提取的道路在膨胀区域内，也就是$90\%$的道路误差小于$1.6m$，同时可以看出$80\%$ 的道路误差小于$1m$。
\begin{figure}[H]
\centering
\includegraphics[width=2.8in]{chapter5/extraction/result_chart.png}
\caption{道路提取精度曲线}
\label{curve}
\end{figure}
\section{本章小结}
本章是对本文提出的算法的实验结果与结论的总结说明，可以分为三部分。首先是二维地图构建使用的传感器以及应用于实际比赛的构图结果，并就影响构图精度的因素进行了分析。其次是关于三维重建的实验平台与重建结果精度的说明，定量说明了两个数据集重建精度。最后是道路提取的精度测量，展示了每个过程的实验结果，并就提取的道路精度进行评价。实验的结果验证了本文提出的方法的有效性与真实性。
\newpage
\mbox{}
\newpage
