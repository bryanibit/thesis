\chapter{基于全景图像的高精度地图构建}
\section{引言}
全景图像（Panorama）是指水平角度包含完整$360^\text{o}$的相机得到的二维平面图像。相对于普通单目相机，全景相机可以更完整地呈现无人车周围环境，更适合作为环境地图采集的传感器。
在本章节中，讨论使用全景相机构建车道级别的用于UGV行驶的高精度地图的方法。首先介绍了全景图像与定位信息的采集，而后介绍了全景相机的标定与全景图像预处理，最后阐述了如何通过全景图像构建大范围的高精度地图的方法。

\section{全景图像与定位信息采集}
为了同时采集全景图像信息与高精度定位导航系统信息，本文采用将车辆的定位信息编码为大小一定的QR code（Quick-Response code），放置于每帧全景图像左上角位置，完成系统的信息采集任务。在此介绍一下二维码的编码与解码过程。由于全景图像的帧率为7Hz，惯性导航系统的帧率为20Hz，考虑拼接图像的精度，在没有使用硬件触发的条件下，本文采用最近邻原则，即当接受到一帧全景图像时，编码离当前时刻最近的惯性导航定位信息。由于编码的信息有时间、经纬度、方位角、偏航角与俯仰角6个整数，所以需要的编码信息量很小，本文只采用$25\times25$像素的二维码编码定位信息。

QR code作为一种非常流行的矩阵式二维码，具有空间利用率高，存储数据量大，解码速度快，可以包含字符、数字等不同内容等优点。如图~\ref{qrcode}所示，二维码可分为两部分：功能区和编码区。功能区包含用于二维码定位的位置探测区域，用于校正二维码位置的校正图形区域等，在编码区中，包含数据和纠错码等。二维码的纠错级别越高，则实际存储的数据信息就越少。按照QR code的规则，可以很方便的将定位信息编码为固定像素大小的二维码，进而将该大小的区域放置在每帧全景图像的左上角，完成信息的采集过程。当回放该视频时，可以很容易地对大小固定的编码区进行解码，读取到每帧全景图对应的车辆当前的位置与角度信息等，为图像拼接做准备。

\begin{figure}[!htbp]
	\centering
	\subfigure[QR code示意图]{\includegraphics[width=4.0in]{chapter2/qrcode.png}
    \label{qrcode}}
    \subfigure[Ladybug全景相机]{\includegraphics[width=1.8in]{chapter2/ladybug.jpg}
    \label{ladybug}}
	%\caption{QR code示意图}
\end{figure}

\section{全景图像处理}
Ladybug全景相机具有6个独立的摄像头，如图~\ref{ladybug}所示，可以在球形坐标系下将6个相机图像实时合并为一张全景图，呈现在二维平面空间中。Ladybug相机提供$360^\text{o}$视频串流功能，可以覆盖90\% 的可视球面，具有图像采集、处理和校正功能。在得到Ladybug相机的全景图后，使用逆透视投影（Inverse Perspective Mapping, IPM）将全景图像投影成俯视图。而后将车辆的高精度定位信息编码为二维码，放置于对应的逆透视投影得到的图片的左下角，从而完成图像与对应车体位置的采集与处理，方便后续构建大范围地图。
%\begin{figure}[!htbp]
%	\centering
%	\caption{Ladybug全景相机}
%	\label{ladybug}
%\end{figure}
\begin{figure}[!htbp]
	\centering
	\includegraphics[width=5.0in]{chapter2/para.png}
	\caption{逆透视坐标变换关系}
	\label{para}
\end{figure}
由于LadyBug成像描述在球面坐标系中，IPM投影需要表示在车体坐标系中，地图拼接需要在世界坐标系中完成，在此简单介绍全景图像处理过程涉及的相关坐标系的变换关系。如图~\ref{para}所示，代表全景相机的球面坐标系与车体坐标系的关系，其中在车体坐标系中，绕自身$x$，$y$和$z$旋转，分别代表俯仰角，横滚角和方位角，使用道路形象地代表车辆的行驶方向；在全景坐标系中，球面狭缝与全景图分块成对应关系，如图中虚线箭头所示，得到的全景图的长宽，图片长宽分别代表相对于车体的方位角$\mu$与俯仰角$\nu$。
为了得到全景图像的IPM俯视图，需要标定全景相机相对于车辆的外参：俯仰角$\theta$，横滚角$\phi$和方位角$\varphi$，以及Ladybug相机光心与地面的高度$h$，同时假定车辆周围的环境与地面高度一致。现定义车体坐标系为$\{F_\omega\}=\{X_\omega,Y_\omega,Z_\omega\}$，坐标原点位于车辆后轴中点；定义全景相机坐标系为$\{F_c\}=\{X_c,Y_c,Z_c\}$；定义全景图像坐标为$\{F_i\}=\{\mu,\nu\}$，则车体坐标系中任一点与全景相机坐标系中点的对应关系为：
\begin{equation}
\label{coordiante relation}
P_c = R_\phi R_\theta R^T _\varphi (P_\omega + T)
\end{equation}
其中
\begin{equation}
R_\phi=\left[\begin{array}{ccc}
cos\phi & 0 & -sin\phi \\
0 & 1 & 0 \\
sin\phi & 0 & cos\phi \\
\end{array}
\right]
\label{R-phi}
\end{equation}

\begin{equation}
R_\theta=\left[\begin{array}{ccc}
1 & 0 & 0 \\
0 & cos\theta & sin\theta \\
0 & -sin\theta & cos\theta \\
\end{array}
\right]
\label{R-theta}
\end{equation}

\begin{equation}
R_\varphi=\left[\begin{array}{ccc}
cos(\varphi-\frac{\pi}{2}) & sin(\varphi-\frac{\pi}{2}) & 0 \\
-sin(\varphi-\frac{\pi}{2}) & cos(\varphi-\frac{\pi}{2}) & 0 \\
0 & 0 & 1 \\
\end{array}
\right]
\label{R-varphi}
\end{equation}

\begin{equation}
T=\left[\begin{array}{ccc}
0 \\ 0 \\ -h \\
\end{array}
\right]
\label{h-move}
\end{equation}
进而可以得到全景图像坐标系中的坐标$P_i = [\mu_i, \nu_i]^T$:
\begin{equation}
\label{p-i}
P_i=\left[\begin{array}{ccc}
arctan \frac{y_c}{x_c} \\ arccos \frac{z_c}{||P_c||} \\
\end{array}
\right]
\end{equation}
其中$||P_c||=\sqrt{{X_{P_C}}^2 + {X_{P_C}}^2 + {X_{P_C}}^2}$，即$P_c$的二范数。通过以上算法可以将全景图像（图~\ref{raw-para}）变换得到车体坐标系下的IPM图，显示效果如图~\ref{IPM}所示，图中长宽对应真实地理空间$30m$。

\begin{figure}[!htbp]
	\centering
    \subfigure{
	\includegraphics[width=2.8in]{chapter2/RAW927090958.png}
    }
    \subfigure{
    \includegraphics[width=2.8in]{chapter2/RAW1001103021.png}
    }
	\caption{基于球面坐标的全景图}
	\label{raw-para}
\end{figure}

\begin{figure}[!htbp]
	\centering
    \subfigure{
	\includegraphics[width=2.4in]{chapter2/IPM927090958.png}
    }
    \subfigure{
    \includegraphics[width=2.4in]{chapter2/IPM1001103021.png}
    }
	\caption{逆透视变换结果}
	\label{IPM}
\end{figure}
%\subsubsection{球面坐标系}
%\subsubsection{世界坐标系}
%\subsubsection{车体坐标系}
%\subsubsection{球体相机坐标系}


\section{地图的构建与使用}
使用以上的方法可以得到全景图像的逆透视投影图，以及每张投影图对应的此时车辆位置与方位等信息。进而我们可以得到大范围地图信息，制作大范围行驶地图，为UGV规划与感知提供先验信息。
\subsection{图像拼接}
图像拼接的历史可以追溯到上个世纪，使用的方法也不尽相同，总体上可以分为两类，一类是基于图像特征匹配的拼接方法，另一类是基于图片间相对位置关系的拼接方法。由于本文采用的惯性组合导航系统，在无遮挡，多路径效应较弱的空旷场地，实验精度达到$5cm$ 以内，所以本文采用基于图片间相对位置关系的方法。具体就是将视频流中每帧逆透视投影图片按照二维码解算的航向旋转一定角度，然后按照解算的位置平移一段距离，对所有视频按照上述方法处理，最终得到完整的城区地图。

对于每帧IPM俯视图，车身为无效信息且占据图像大量位置，对地图拼接造成干扰，所以在拼接地图前，需要将车身移除。由于全景图变换为IPM投影图时，将IPM俯视图变换到车体坐标系中，所以任何一张IPM俯视图的车辆位置与方位是固定的：车辆后轴中心位于图片横轴的中心，纵轴靠下的$1/3$位置处，航向朝上。如图~\ref{carmask}所示。据此设计一个掩码（Mask），在拼接过程中将车辆去掉，只拼接剩下的像素不为零的部分。

\begin{figure}[!htbp]
	\centering
    \subfigure{
	\includegraphics[width=2.0in]{chapter2/IPM927090958.png}
    }
    \subfigure{
	\includegraphics[width=2.0in]{chapter2/res.png}
    }
    \subfigure{
	\includegraphics[width=2.0in]{chapter2/car_mask.png}
    }
    \subfigure{
	\includegraphics[width=2.0in]{chapter2/area_num.png}
    }
	\caption{IPM图拼接处理过程}
	\label{carmask}
\end{figure}

在拼接过程中，因为所需拼接的地理空间过大，图片过多，而内存限制了单张图片的大小，所以本文设计了区号标记的方法。具体做法为：将视频流中图片按照位置和航向拼接为多张$28000\times7000$像素的图片（图~\ref{carmask}中橙色方框），由于每个像素代表实际地理空间的大小为$0.06m$，即每张拼接后的图片代表的物理空间大小为$1680m\times420m$。设置整个地图的坐标原点（图~\ref{carmask}红色圆点所示）为某一固定经纬度坐标，IPM图对应的经纬度与该点对比后，计算出该帧IPM图应该放置于哪个区，而后可以拼接成多张橙色大小的图片。一个橙色方框代表一个区域，对应一个区号，这种存在重叠区域的区号法则有效的解决了图像拼接过程中边缘缺失的问题。边缘缺失是指系统拼接得到的橙色图的边缘没有道路像素，这是由于每帧IPM图的旋转中点无法通过平移放置于接近橙色图的边缘位置，因为这样IPM图的其他像素就落在橙色图区域之外，重叠区域的存在可以有效解决该问题。最后只需要保留上图~\ref{carmask}的绿色框表示的区域和该区域的区号，这样就可以按照区号将拼接的图片在Photoshop中拼接为更大的图片，为后续GIS数据库中构建地图数据库的底图做准备。

\subsection{基于GIS数据库生成无人驾驶车辆行驶地图}

在得到数张Photoshop拼接的更大的图片后，按照上图~\ref{carmask}的分区原则可以得到每张图片四个顶点的地理坐标。依托Supermap(GIS)软件完成拼接地图的金字塔图生成，作为GIS数据库的一个图层。这样构建的地图并不能直接用于UGV导航或规划，我们将得到的底图作为GIS数据库的一个图层，根据底图可以得到车道级别的道路拓扑结构，该拓扑作为GIS数据库的另一个图层，在线段与线段的节点上添加各种属性，例如车道数量，限速，红路灯和路口等，即可实现全局路径规划等功能。图~\ref{road-cross}中左图为拼接的路口图片，右图中绿色线段为GIS数据库的道路拓扑。

\begin{figure}[!htbp]
	\centering
    \subfigure{
	\includegraphics[width=2.8in]{chapter2/road_cross.png}
    }
    \subfigure{
	\includegraphics[width=2.8in]{chapter2/road_net.png}
    }
	\caption{拼接路口在GIS数据库显示结果}
	\label{road-cross}
\end{figure}

\section{本章小结}
鉴于高精度地图在UGV自主导航与决策规划中的重要作用，本章提出了一种新的高精度地图构建方法，并给出了地图构建的实现流程。在该方法中，高精度组合导航系统的位置航向输出编码为固定大小的二维码，嵌入全景图像视频中，这样保证了全景图像与定位信息同步，完成系统数据的采集工作。而后在离线拼接地图过程中，将全景图像转换到车体坐标系中，完成IPM过程，并将每个IPM图像通过车辆的高精度定位信息，旋转、平移拼接为范围较大的地图。但由于地理空间广阔，计算机内存限制等原因，本章采用将采集的视频拼接为多个大小一致的图像，并对这些图像编号，以方便后序的手工拼接与导入GIS 数据库生成完整的道路地图。最后将地图生成GIS数据库的图层，完成道路拓扑构建与道路属性添加的任务，第5章实验环节展示了本章提出的方法在实际无人驾驶比赛的效果，验证本章提出的方法有效性。
但是本章获取的二维地图存在肉眼可见变形、包含地面信息较少的问题，所以下文将介绍另外一种构建地图方法，可以通过二维图片恢复地理空间的三维结构。
