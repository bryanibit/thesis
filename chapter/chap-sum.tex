
\chapter*{总结与展望}

\phantomsection
\addcontentsline{toc}{chapter}{总结与展望} %向目录中添加条目，以章的名义

\noindent$\displaystyle \textbf{总结} $

无人驾驶的快速发展使高精度地图构建越来越重要，针对这一需求，本文提出了构建高精度二维地图与三维地图的方法，同时为了更好地将地图应用于UGV导航，本文提出了从高空视角的航拍图像中提取道路的方法。本文的主要工作与创新点如下：

1. 提出通过全景图像构建二维地图的方法。首先设计了带有高精度定位信息的全景图像采集系统，将定位信息编码为二维码，嵌入全景图像中；而后通过坐标变换将全景图像转换为以UGV为中心俯视效果的逆透视投影图，将二维码解码为航向与位置信息，据此将一系列逆透视投影图拼接为大范围二维场景地图。利用GIS平台将拼接的二维地图转化为GIS中的图层，并添加道路拓扑、属性等信息，构建适用于无人驾驶的地图数据库。该数据库应用于真实无人车比赛，获得较好的成绩。

2. 研究由航拍图像结合当前先进的SfM技术，获得地理空间的三维场景的方法。首先对数据集中每张航拍图像进行SIFT特征提取，将图像由二维矩阵表示为一维SIFT特征描述子，基于近似最近邻算法计算特征描述子之间的距离，得到初始匹配的特征点，并采用对极约束过滤错误的匹配点，而后通过track序号对应的图像名称，删除逻辑关系不正确的匹配点，通过特征匹配得到数据集图像间的关联关系。而后采用八点法计算匹配特征点数目最多的两张图像之间的相机位姿关系；其中计算两视图单应性变换的外点比例大于某阈值，保证两视图的相机位姿非纯旋转或平面投影关系，从而保证八点法可以由两视图得到相机位姿。最后增量式的加入其余图像，得到所有图像的相机位姿关系与整个地理空间的稀疏点云。在整个重建过程中，使用光束平差法优化相机位姿与稀疏点云，本文充分利用图像中GNSS数据最小化相机中心距离，优化多视图间的旋转平移关系，作为光束平差法的一部分。

3. 针对航拍图像拥有较高的分辨率，研究采用基于块的点云稠密方法。为了计算每张图像的深度图，通过SfM获得的图像相机位姿关系，计算匹配图像间的相机夹角与基线距离，据此为每张图像选取多张参考图，以去均值NCC作为判据，由每张图像的参考图计算其深度图，经过深度图精炼和融合去除错误和冗余的深度值，从而得到整个地理空间的稠密点云。
%本文采用多种方法避免将错误匹配点用于重建，包括最近邻匹配法去除模糊的匹配点，使用对极约束计算匹配点间的几何关系，从而去除一部分误差大的匹配点，通过track序号对应的图像名称，删除逻辑关系不正确的匹配点。

4. 基于以上工作，从航拍视角的二维图像中提取道路的方法，首先选取一部分道路图像作为训练样本，根据道路的光谱特征一致性，使用最小二乘法拟合训练样本，与测试集图像对比得到测试集图像的道路二值图。其次，采用开闭运算平滑二值图，同时设计多边形检测的方法，
去除房屋边缘等非道路区域的干扰。
并对提取的道路进行拓扑细化，得到由单像素构成的道路拓扑网络，基于此可以直接利用GIS数据平台生成线数据集，用于UGV自主导航规划。

\noindent$\displaystyle \textbf{展望} $

针对无人驾驶的高精度地图构建一直是一个非常活跃的研究领域，随着相关传感器技术与感知技术的提高，构建高精度的三维地图，并将三维地图用于无人驾驶仿真与路测的研究将进一步深入，结合本文的研究内容与最新进展，有以下方面有待提高：

1. 二维地图构建方法对远离全景相机的地面区域目前存在变形、精度变低的缺点，在未来可以加入激光雷达，将激光雷达点云与全景相机配准并融合二者数据，得到更高精度三维的带有真实纹理的点云数据。

2. 本文基于SfM框架进行地理空间三维场景建模研究，如何选取更合适的两视图用于初始化重建，对于有序图片提高重建效率，使用GPU进行并行计算等，这些问题都没有涉及。因此在未来的研究中可以尝试吸取更先进的SfM算法思想，进一步提高完善三维重建技术。

3. 本文的道路提取算法通过拟合道路光谱特征，得到道路区域的二值图像。但是对于道路颜色特征差别较大的区域，效果不理想，尤其是房屋干扰很难消除，所以在未来将采用深度学习的方法提取道路的抽象特征，并应用于大范围道路提取，相信在针对道路的二分类中，当道路训练样本足够多时，算法将获得较好的效果。



